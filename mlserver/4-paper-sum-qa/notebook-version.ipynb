{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      2\u001b[0m sentiment  \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39msentiment-analysis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m sentiment(\u001b[39m\"\u001b[39m\u001b[39mmamooli weather\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     29\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     33\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     logging,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     48\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/dependency_versions_check.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdependency_versions_table\u001b[39;00m \u001b[39mimport\u001b[39;00m deps\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     20\u001b[0m \u001b[39m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# order specific notes:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     26\u001b[0m pkgs_to_check_at_runtime \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpython tqdm regex requests packaging filelock numpy tokenizers\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/utils/__init__.py:46\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdoc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     27\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     ContextManagers,\n\u001b[1;32m     35\u001b[0m     ExplicitEnum,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     to_py_obj,\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     48\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m     49\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m     50\u001b[0m     HUGGINGFACE_CO_PREFIX,\n\u001b[1;32m     51\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m     52\u001b[0m     PYTORCH_PRETRAINED_BERT_CACHE,\n\u001b[1;32m     53\u001b[0m     PYTORCH_TRANSFORMERS_CACHE,\n\u001b[1;32m     54\u001b[0m     S3_BUCKET_PREFIX,\n\u001b[1;32m     55\u001b[0m     TRANSFORMERS_CACHE,\n\u001b[1;32m     56\u001b[0m     TRANSFORMERS_DYNAMIC_MODULE_NAME,\n\u001b[1;32m     57\u001b[0m     EntryNotFoundError,\n\u001b[1;32m     58\u001b[0m     PushToHubMixin,\n\u001b[1;32m     59\u001b[0m     RepositoryNotFoundError,\n\u001b[1;32m     60\u001b[0m     RevisionNotFoundError,\n\u001b[1;32m     61\u001b[0m     cached_path,\n\u001b[1;32m     62\u001b[0m     default_cache_path,\n\u001b[1;32m     63\u001b[0m     define_sagemaker_information,\n\u001b[1;32m     64\u001b[0m     filename_to_url,\n\u001b[1;32m     65\u001b[0m     get_cached_models,\n\u001b[1;32m     66\u001b[0m     get_file_from_repo,\n\u001b[1;32m     67\u001b[0m     get_from_cache,\n\u001b[1;32m     68\u001b[0m     get_full_repo_name,\n\u001b[1;32m     69\u001b[0m     get_list_of_files,\n\u001b[1;32m     70\u001b[0m     has_file,\n\u001b[1;32m     71\u001b[0m     hf_bucket_url,\n\u001b[1;32m     72\u001b[0m     http_get,\n\u001b[1;32m     73\u001b[0m     http_user_agent,\n\u001b[1;32m     74\u001b[0m     is_local_clone,\n\u001b[1;32m     75\u001b[0m     is_offline_mode,\n\u001b[1;32m     76\u001b[0m     is_remote_url,\n\u001b[1;32m     77\u001b[0m     send_example_telemetry,\n\u001b[1;32m     78\u001b[0m     url_to_filename,\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     80\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     81\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     82\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m     torch_version,\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    151\u001b[0m WEIGHTS_NAME \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpytorch_model.bin\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/utils/hub.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39muuid\u001b[39;00m \u001b[39mimport\u001b[39;00m uuid4\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mzipfile\u001b[39;00m \u001b[39mimport\u001b[39;00m ZipFile, is_zipfile\n\u001b[0;32m---> 37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfilelock\u001b[39;00m \u001b[39mimport\u001b[39;00m FileLock\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m HfFolder, Repository, create_repo, list_repo_files, whoami\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment  = pipeline(\"sentiment-analysis\")\n",
    "sentiment(\"mamooli weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 ('jupyter-test')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n jupyter-test ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator  = pipeline(\"translation_es_to_en\")\n",
    "translator(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unknown task text-classification, available tasks are ['feature-extraction', 'sentiment-analysis', 'ner', 'question-answering', 'table-question-answering', 'fill-mask', 'summarization', 'translation', 'text2text-generation', 'text-generation', 'zero-shot-classification', 'conversational', 'translation_XX_to_YY']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/cc/infernece-pipeline-joint-optimization/pipelines/seldon-prototype/paper-sum-qa/notebook-version.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/pipelines/seldon-prototype/paper-sum-qa/notebook-version.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/pipelines/seldon-prototype/paper-sum-qa/notebook-version.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m summerize  \u001b[39m=\u001b[39m pipeline(task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-classification\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbert-base-uncased\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/pipelines/seldon-prototype/paper-sum-qa/notebook-version.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m summerize(\u001b[39m\"\u001b[39m\u001b[39mIf hearings or trials cannot take place because there are no barristers present to represent defendants, there won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be any trials in which criminals are sent to prison and those who are innocent are acquitted. Victims, like defendants, will be left in limbo, unsure when they will see justice. Tentative plans to broker a deal behind the scenes by bringing forward payments have failed - partly because there is simply no trust between the profession and ministers who wont meet them.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/central/lib/python3.8/site-packages/transformers/pipelines/__init__.py:342\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mUtility factory method to build a :class:`~transformers.Pipeline`.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m    >>> pipeline('ner', model=model, tokenizer=tokenizer)\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m# Retrieve the task\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m targeted_task, task_options \u001b[39m=\u001b[39m check_task(task)\n\u001b[1;32m    344\u001b[0m \u001b[39m# Use default model/config/tokenizer for the task if no model is provided\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[39m# At that point framework might still be undetermined\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/central/lib/python3.8/site-packages/transformers/pipelines/__init__.py:236\u001b[0m, in \u001b[0;36mcheck_task\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[39mreturn\u001b[39;00m targeted_task, (tokens[\u001b[39m1\u001b[39m], tokens[\u001b[39m3\u001b[39m])\n\u001b[1;32m    234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid translation task \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m, use \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtranslation_XX_to_YY\u001b[39m\u001b[39m'\u001b[39m\u001b[39m format\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown task \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m, available tasks are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(SUPPORTED_TASKS\u001b[39m.\u001b[39mkeys()) \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtranslation_XX_to_YY\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unknown task text-classification, available tasks are ['feature-extraction', 'sentiment-analysis', 'ner', 'question-answering', 'table-question-answering', 'fill-mask', 'summarization', 'translation', 'text2text-generation', 'text-generation', 'zero-shot-classification', 'conversational', 'translation_XX_to_YY']\""
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summerize  = pipeline(task=\"text-classification\", model='bert-base-uncased')\n",
    "summerize(\"If hearings or trials cannot take place because there are no barristers present to represent defendants, there won't be any trials in which criminals are sent to prison and those who are innocent are acquitted. Victims, like defendants, will be left in limbo, unsure when they will see justice. Tentative plans to broker a deal behind the scenes by bringing forward payments have failed - partly because there is simply no trust between the profession and ministers who wont meet them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unknown task text-classification, available tasks are ['feature-extraction', 'sentiment-analysis', 'ner', 'question-answering', 'table-question-answering', 'fill-mask', 'summarization', 'translation', 'text2text-generation', 'text-generation', 'zero-shot-classification', 'conversational', 'translation_XX_to_YY']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/cc/infernece-pipeline-joint-optimization/pipelines/seldon-prototype/paper-sum-qa/notebook-version.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/pipelines/seldon-prototype/paper-sum-qa/notebook-version.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/pipelines/seldon-prototype/paper-sum-qa/notebook-version.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m translator  \u001b[39m=\u001b[39m pipeline(task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-classification\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdinalzein/xlm-roberta-base-finetuned-language-identification\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/pipelines/seldon-prototype/paper-sum-qa/notebook-version.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m translator(\u001b[39m\"\u001b[39m\u001b[39mHello, how are you?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/central/lib/python3.8/site-packages/transformers/pipelines/__init__.py:342\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mUtility factory method to build a :class:`~transformers.Pipeline`.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m    >>> pipeline('ner', model=model, tokenizer=tokenizer)\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m# Retrieve the task\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m targeted_task, task_options \u001b[39m=\u001b[39m check_task(task)\n\u001b[1;32m    344\u001b[0m \u001b[39m# Use default model/config/tokenizer for the task if no model is provided\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[39m# At that point framework might still be undetermined\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/central/lib/python3.8/site-packages/transformers/pipelines/__init__.py:236\u001b[0m, in \u001b[0;36mcheck_task\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[39mreturn\u001b[39;00m targeted_task, (tokens[\u001b[39m1\u001b[39m], tokens[\u001b[39m3\u001b[39m])\n\u001b[1;32m    234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid translation task \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m, use \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtranslation_XX_to_YY\u001b[39m\u001b[39m'\u001b[39m\u001b[39m format\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown task \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m, available tasks are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(SUPPORTED_TASKS\u001b[39m.\u001b[39mkeys()) \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtranslation_XX_to_YY\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unknown task text-classification, available tasks are ['feature-extraction', 'sentiment-analysis', 'ner', 'question-answering', 'table-question-answering', 'fill-mask', 'summarization', 'translation', 'text2text-generation', 'text-generation', 'zero-shot-classification', 'conversational', 'translation_XX_to_YY']\""
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator  = pipeline(task=\"text-classification\", model=\"dinalzein/xlm-roberta-base-finetuned-language-identification\")\n",
    "translator(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration clean-data_dir=%2F\n",
      "Reusing dataset librispeech_asr_demo (/home/cc/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_demo/clean-data_dir=%2F/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/miniconda3/envs/central/lib/python3.8/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:557: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  input_lengths = (input_lengths - 1) // 2 + 1\n",
      "/home/cc/miniconda3/envs/central/lib/python3.8/site-packages/transformers/generation_utils.py:1777: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['</s> mister quilter is the apostle of the middle classes and we are glad to welcome his gospel</s>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\", data_dir=\"/\")\n",
    "\n",
    "inputs = processor(ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n",
    "generated_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('jupyter-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "59072ed32e7a3308a4a098da951e9f72b7536c5ea58a102a2f27175436f85f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
